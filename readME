# **Face Classification and Clustering Project**

## **Table of Contents**
- [**Abstract**](#abstract)
- [**Introduction**](#introduction)
- [**Dataset**](#dataset)
- [**Theoretical Background**](#theoretical-background)
- [**Model Explanation**](#model-explanation)
- [**Getting Started**](#getting-started)
- [**Usage**](#usage)
- [**Contributors**](#contributors)
- [**License**](#license)


## Abstract
The aim of this project is to classify faces from a virtual meeting using an unsupervised method. While humans can easily perform this task, even under varying light conditions and when faces change due to age or accessories, automating face classification is a challenging problem. In this project, we focus on face recognition within a dataset containing images of people from a virtual meeting. The approach involves extracting embeddings from the images and clustering these embeddings to group faces based on the person's identity.

## Introduction
Face classification is a widely used technique employed by companies like Google and Facebook for various applications. In this project, we adopt an unsupervised approach, which does not require labeled data for training. Unsupervised learning, specifically DBSCAN (Density-Based Spatial Clustering of Applications with Noise), is utilized to analyze and cluster unlabeled datasets. DBSCAN identifies clusters of data points based on their proximity, making it suitable for tasks like face clustering.

## Dataset
The dataset consists of three folders containing images of individuals who attended the virtual meeting. The dataset presents some challenges, as it includes images of people wearing masks and images without any faces. In total, there are 57,902 images across the three folders. Due to limitations in time and computational resources, this project initially uses a subset of 200 photos for clustering, with the intention of extending it to process the entire dataset.

## Theoretical Background
### Multi-task Cascaded Convolutional Networks (MTCNN)
MTCNN is a framework developed for both face detection and alignment. It consists of three stages: Proposal Network (P-Net), Refine Network (R-Net), and Output Network (O-Net), each performing specific tasks in the detection and alignment process.

### Face Embeddings
Face embeddings are vectors that represent facial features extracted from images. In this project, we utilize the FaceNet model to generate embeddings for facial images. These embeddings allow for efficient face recognition and clustering.

### Clustering using DBSCAN
DBSCAN is a density-based clustering algorithm that groups data points based on their density and proximity. It requires two key parameters: 'eps' (neighborhood radius) and 'MinPts' (minimum number of neighbors). By tuning these parameters, we can effectively cluster the generated face embeddings.

## Model Explanation
The project follows these main steps:

1. Extracting Face: Utilize the MTCNN detector to locate and crop faces from input images, cleaning the dataset by ignoring images with masks or no faces.

2. Creating Face Embeddings: Use the FaceNet model to preprocess faces and generate 128-dimensional face embeddings for each image.

3. Clustering using DBSCAN: Apply the DBSCAN clustering algorithm to group face embeddings based on similarity, effectively identifying individuals in the virtual meeting.

## Getting Started
To get started with this project, follow these steps:

1. Clone this repository to your local machine.

2. Install the required dependencies (list them in a separate section or a requirements file).

3. Follow the usage instructions below to run the project.

## Usage
[Provide detailed instructions on how to use the project, including any command-line arguments or configuration settings.]

## Contributor
- Paruchuri Murari Pavan Sai

## License
[Specify the license for your project, e.g., MIT License, Apache License, etc.]
